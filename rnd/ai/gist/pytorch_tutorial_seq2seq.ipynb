{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "pytorch_tutorial_seq2seq.ipynb",
   "provenance": [
    {
     "file_id": "1T1ffrTy_IzywVb2vqlzLpoU9nYg0SS3n",
     "timestamp": 1594872238872
    },
    {
     "file_id": "1b1BCvhnPeHSzWxvlCspVzAKmPC4OTGI5",
     "timestamp": 1594533544666
    },
    {
     "file_id": "1DLZSA_B9_tgwEeBMUW_B10EBi9tvnCFF",
     "timestamp": 1593824930085
    }
   ],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "KoN_QwOdGyWj",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1594873943722,
     "user_tz": 420,
     "elapsed": 707,
     "user": {
      "displayName": "Xin Heng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghih2qYah2j147oGatNY6HQBB8nFM3Wl0KUFG7X=s64",
      "userId": "10806682243950504635"
     }
    },
    "outputId": "05fd52a1-e505-48b2-8b4f-192dec817a41"
   },
   "source": [
    "\"\"\"\n",
    "Links\n",
    "  https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
    "\"\"\"\n",
    "# !pip install plotly_express\n",
    "# !pip install torchcontrib"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "'\\nLinks\\n  https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\\n'"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 1
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jziiW-1VlXhB",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1594873944343,
     "user_tz": 420,
     "elapsed": 1318,
     "user": {
      "displayName": "Xin Heng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghih2qYah2j147oGatNY6HQBB8nFM3Wl0KUFG7X=s64",
      "userId": "10806682243950504635"
     }
    },
    "outputId": "122ca4f7-fb66-451b-e3ee-09b3b80f4354"
   },
   "source": [
    "# Libraries and general settings\n",
    "from google.colab import drive\n",
    "from io import open\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "#\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# import torchcontrib\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "pd.set_option(\"precision\", 4)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"max_colwidth\", None)\n",
    "\n",
    "drive.mount(\"/content/gdrive\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"%d GPU(s) available, namely %s\" % (torch.cuda.device_count(), torch.cuda.get_device_name(0)))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU available, using CPU instead.\")"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
      "1 GPU(s) available, namely Tesla K80\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QOE2HSieI16a",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1594873944344,
     "user_tz": 420,
     "elapsed": 1308,
     "user": {
      "displayName": "Xin Heng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghih2qYah2j147oGatNY6HQBB8nFM3Wl0KUFG7X=s64",
      "userId": "10806682243950504635"
     }
    }
   },
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "\n",
    "def readLangs(lang1, lang2, data_folder: str = \"/content/gdrive/My Drive/xheng/data/data\", reverse: bool = False):\n",
    "    \"\"\"To read the data file we will split the file into lines, and then split lines into pairs.\n",
    "    The files are all English → Other Language, so if we want to translate from Other Language → English,\n",
    "    I added the reverse flag to reverse the pairs.\n",
    "    \"\"\"\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open(\"%s/%s-%s.txt\" % (data_folder, lang1, lang2), encoding=\"utf-8\").read().strip().split(\"\\n\")\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split(\"\\t\")] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    \"\"\"Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\"\"\"\n",
    "    return \"\".join(c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\")\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    \"\"\"Lowercase, trim, and remove non-letter characters\"\"\"\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "# Since there are a lot of example sentences and we want to train something quickly, we’ll trim the data set\n",
    "# to only relatively short and simple sentences. Here the maximum length is 10 words (that includes ending\n",
    "# punctuation) and we’re filtering to sentences that translate to the form “I am” or “He is” etc.\n",
    "# (accounting for apostrophes replaced earlier).\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \",\n",
    "    \"i m \",\n",
    "    \"he is\",\n",
    "    \"he s \",\n",
    "    \"she is\",\n",
    "    \"she s \",\n",
    "    \"you are\",\n",
    "    \"you re \",\n",
    "    \"we are\",\n",
    "    \"we re \",\n",
    "    \"they are\",\n",
    "    \"they re \",\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(\" \")) < MAX_LENGTH and len(p[1].split(\" \")) < MAX_LENGTH and p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3w--RSEKNqRP",
    "colab_type": "code",
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1594873950006,
     "user_tz": 420,
     "elapsed": 6963,
     "user": {
      "displayName": "Xin Heng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghih2qYah2j147oGatNY6HQBB8nFM3Wl0KUFG7X=s64",
      "userId": "10806682243950504635"
     }
    },
    "outputId": "50cb5fcf-64e5-4d6f-afcc-e574762a85cd"
   },
   "source": [
    "def prepareData(lang1: str, lang2: str, reverse: bool = False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse=reverse)\n",
    "    print(\"Read %d sentence pairs\" % len(pairs))\n",
    "\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %d sentence pairs\" % len(pairs))\n",
    "\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData(\"eng\", \"fra\", reverse=True)\n",
    "print(random.choice(pairs))"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4345\n",
      "eng 2803\n",
      "['c est une fille intelligente .', 'she s a smart girl .']\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-d0dkDb6FqMq",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1594873950008,
     "user_tz": 420,
     "elapsed": 6955,
     "user": {
      "displayName": "Xin Heng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghih2qYah2j147oGatNY6HQBB8nFM3Wl0KUFG7X=s64",
      "userId": "10806682243950504635"
     }
    }
   },
   "source": [
    "# The Encoder of a seq2seq network is a RNN that outputs some value for every word from the input sentence. For every\n",
    "# input word the encoder outputs a vector and a hidden state, and uses the hidden state for the next input word.\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "\n",
    "# Simple Decoder\n",
    "# In the simplest seq2seq decoder we use only last output of the encoder. This last output is sometimes called\n",
    "# the context vector as it encodes context from the entire sequence. This context vector is\n",
    "# used as the initial hidden state of the decoder.\n",
    "\n",
    "# At every step of decoding, the decoder is given an input token and hidden state. The initial input token is\n",
    "# the start-of-string <SOS> token, and the first hidden state is the context vector (the encoder’s last hidden state).\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DRx0InBRHHfo",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1594873950010,
     "user_tz": 420,
     "elapsed": 6952,
     "user": {
      "displayName": "Xin Heng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghih2qYah2j147oGatNY6HQBB8nFM3Wl0KUFG7X=s64",
      "userId": "10806682243950504635"
     }
    }
   },
   "source": [
    "# Preparing Training Data\n",
    "# To train, for each pair we will need an input tensor (indexes of the words in the input sentence) and target tensor\n",
    "# (indexes of the words in the target sentence). While creating these vectors we will append the EOS token to both\n",
    "# sequences.\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(\" \")]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "khkZ87Bg4N8g",
    "colab_type": "code",
    "colab": {},
    "executionInfo": {
     "status": "ok",
     "timestamp": 1594873969975,
     "user_tz": 420,
     "elapsed": 761,
     "user": {
      "displayName": "Xin Heng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghih2qYah2j147oGatNY6HQBB8nFM3Wl0KUFG7X=s64",
      "userId": "10806682243950504635"
     }
    }
   },
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(\n",
    "    input_tensor,\n",
    "    target_tensor,\n",
    "    encoder,\n",
    "    decoder,\n",
    "    encoder_optimizer,\n",
    "    decoder_optimizer,\n",
    "    criterion,\n",
    "    max_length=MAX_LENGTH,\n",
    "):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length\n",
    "\n",
    "\n",
    "# This is a helper function to print time elapsed and estimated time remaining given the current time and progress %.\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (- %s)\" % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print(\"%s (%d %d%%) %.4f\" % (timeSince(start, iter / n_iters), iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.switch_backend(\"agg\")\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append(\"<EOS>\")\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[: di + 1]\n",
    "\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print(\">\", pair[0])\n",
    "        print(\"=\", pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = \" \".join(output_words)\n",
    "        print(\"<\", output_sentence)\n",
    "        print(\"\")"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5IB8jytx4kpj",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 911
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1594875928172,
     "user_tz": 420,
     "elapsed": 1953967,
     "user": {
      "displayName": "Xin Heng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghih2qYah2j147oGatNY6HQBB8nFM3Wl0KUFG7X=s64",
      "userId": "10806682243950504635"
     }
    },
    "outputId": "45aa5424-14bb-4eb5-9485-2f2dc86710bb"
   },
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)\n",
    "\n",
    "evaluateRandomly(encoder1, attn_decoder1)"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "2m 15s (- 31m 42s) (5000 6%) 2.8422\n",
      "4m 26s (- 28m 50s) (10000 13%) 2.2751\n",
      "6m 36s (- 26m 25s) (15000 20%) 1.9674\n",
      "8m 45s (- 24m 5s) (20000 26%) 1.7568\n",
      "10m 56s (- 21m 52s) (25000 33%) 1.5780\n",
      "13m 4s (- 19m 36s) (30000 40%) 1.3686\n",
      "15m 12s (- 17m 22s) (35000 46%) 1.2543\n",
      "17m 20s (- 15m 10s) (40000 53%) 1.1135\n",
      "19m 28s (- 12m 58s) (45000 60%) 1.0116\n",
      "21m 38s (- 10m 49s) (50000 66%) 0.9331\n",
      "23m 50s (- 8m 40s) (55000 73%) 0.8186\n",
      "25m 59s (- 6m 29s) (60000 80%) 0.7579\n",
      "28m 11s (- 4m 20s) (65000 86%) 0.6924\n",
      "30m 20s (- 2m 10s) (70000 93%) 0.6456\n",
      "32m 30s (- 0m 0s) (75000 100%) 0.5887\n",
      "> il va bien .\n",
      "= he s all right .\n",
      "< he is doing well . <EOS>\n",
      "\n",
      "> il est pauvre .\n",
      "= he is poor .\n",
      "< he s a . <EOS>\n",
      "\n",
      "> je songe a y aller .\n",
      "= i m thinking of going .\n",
      "< i m counting to go . <EOS>\n",
      "\n",
      "> elle prepare le dejeuner .\n",
      "= she is making dinner .\n",
      "< she is making dinner . <EOS>\n",
      "\n",
      "> je ne suis pas un professionnel .\n",
      "= i m not a professional .\n",
      "< i m not a professional . <EOS>\n",
      "\n",
      "> je suis fascinee par les chats .\n",
      "= i m fascinated by cats .\n",
      "< i m fascinated by cats . <EOS>\n",
      "\n",
      "> il t attend chez lui .\n",
      "= he s waiting for you at home .\n",
      "< he s waiting for you at home . <EOS>\n",
      "\n",
      "> tu es intrepide .\n",
      "= you re fearless .\n",
      "< you re fearless . <EOS>\n",
      "\n",
      "> je suis assez fatiguee .\n",
      "= i m quite tired .\n",
      "< i m quite tired . <EOS>\n",
      "\n",
      "> vous n etes pas gros .\n",
      "= you re not fat .\n",
      "< you re not fat . <EOS>\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CK71YBVp4_m9",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1594875929699,
     "user_tz": 420,
     "elapsed": 1498,
     "user": {
      "displayName": "Xin Heng",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghih2qYah2j147oGatNY6HQBB8nFM3Wl0KUFG7X=s64",
      "userId": "10806682243950504635"
     }
    },
    "outputId": "e91256e9-6b1b-494c-f725-47365474fdc4"
   },
   "source": [
    "\"\"\"Visualizing Attention\n",
    "A useful property of the attention mechanism is its highly interpretable outputs. Because it is used to weight \n",
    "specific encoder outputs of the input sequence, we can imagine looking where the network is focused most at each \n",
    "time step\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap=\"bone\")\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([\"\"] + input_sentence.split(\" \") + [\"<EOS>\"], rotation=90)\n",
    "    ax.set_yticklabels([\"\"] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(encoder1, attn_decoder1, input_sentence)\n",
    "    print(\"input =\", input_sentence)\n",
    "    print(\"output =\", \" \".join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "\n",
    "evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n",
    "evaluateAndShowAttention(\"elle est trop petit .\")\n",
    "evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
    "evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "input = elle a cinq ans de moins que moi .\n",
      "output = she s six years older than me . <EOS>\n",
      "input = elle est trop petit .\n",
      "output = she s too busy . <EOS>\n",
      "input = je ne crains pas de mourir .\n",
      "output = i m not going to die . <EOS>\n",
      "input = c est un jeune directeur plein de talent .\n",
      "output = he s a talented young of of of . .\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eJv3yjt3_fQD",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}