{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"AL3aSq91cyRA","colab_type":"code","colab":{}},"source":["\"\"\"\n","Tutorials:\n","- http://mccormickml.com/2019/07/22/BERT-fine-tuning/\n","\"\"\"\n","import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","assert device_name == \"/device:GPU:0\", \"device name is: '{}'. GPU device not found\".format(device_name)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RTFFA84yeCXO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"c0d612be-9211-46e2-82fe-12d39d653123","executionInfo":{"status":"ok","timestamp":1577741875640,"user_tz":480,"elapsed":94703,"user":{"displayName":"Xin Heng","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQvHFMPmbZ2ZkxcYliAOrSQhkYHgGNGai5QhEn=s64","userId":"10806682243950504635"}}},"source":["! pip3 install torch torchvision\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting torch\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/95/90e8c4c31cfc67248bf944ba42029295b77159982f532c5689bcfe4e9108/torch-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (734.6MB)\n","\u001b[K     |████████████████████████████████| 734.6MB 23kB/s \n","\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n","Installing collected packages: torch\n","Successfully installed torch-1.3.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"es4N9EMovmKH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"b29c6087-af3d-4378-b8af-78ecad19a869","executionInfo":{"status":"ok","timestamp":1577742010950,"user_tz":480,"elapsed":893,"user":{"displayName":"Xin Heng","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQvHFMPmbZ2ZkxcYliAOrSQhkYHgGNGai5QhEn=s64","userId":"10806682243950504635"}}},"source":["import torch\n","\n","device = torch.device(\"cuda\")\n","print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","print('We will use the GPU:', torch.cuda.get_device_name(0))\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mKHvrP8nv0ls","colab_type":"code","colab":{}},"source":["!pip install transformers"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ndm0Ga9_wTmF","colab_type":"code","colab":{}},"source":["!pip install wget"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yxw9ckfuwiKu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"outputId":"dd6a5025-a495-49a4-a7cf-b888fd86ddb4","executionInfo":{"status":"ok","timestamp":1577742288466,"user_tz":480,"elapsed":3520,"user":{"displayName":"Xin Heng","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQvHFMPmbZ2ZkxcYliAOrSQhkYHgGNGai5QhEn=s64","userId":"10806682243950504635"}}},"source":["import wget\n","import os\n","url = \"https://nyu-mll.github.io/CoLA/cola_public_1.1.zip\"\n","if not os.path.exists('./cola_public_1.1.zip'):\n","    wget.download(url, './cola_public_1.1.zip')\n","    print(\"Successfully downloaded cola_public_1.1.zip\")\n","if not os.path.exists('./cola_public/'):\n","    !unzip cola_public_1.1.zip"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Successfully downloaded cola_public_1.1.zip\n","Archive:  cola_public_1.1.zip\n","   creating: cola_public/\n","  inflating: cola_public/README      \n","   creating: cola_public/tokenized/\n","  inflating: cola_public/tokenized/in_domain_dev.tsv  \n","  inflating: cola_public/tokenized/in_domain_train.tsv  \n","  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n","   creating: cola_public/raw/\n","  inflating: cola_public/raw/in_domain_dev.tsv  \n","  inflating: cola_public/raw/in_domain_train.tsv  \n","  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o5f6-h96wwC1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":393},"outputId":"4d237111-cd21-41b6-b234-1750100dca09","executionInfo":{"status":"ok","timestamp":1577742330969,"user_tz":480,"elapsed":896,"user":{"displayName":"Xin Heng","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQvHFMPmbZ2ZkxcYliAOrSQhkYHgGNGai5QhEn=s64","userId":"10806682243950504635"}}},"source":["import pandas as pd\n","df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', \n","                 header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n","print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n","df.sample(10)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Number of training sentences: 8,551\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence_source</th>\n","      <th>label</th>\n","      <th>label_notes</th>\n","      <th>sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>64</th>\n","      <td>gj04</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>Bill floated into the cave.</td>\n","    </tr>\n","    <tr>\n","      <th>1103</th>\n","      <td>r-67</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>John is taller than Bill is.</td>\n","    </tr>\n","    <tr>\n","      <th>4155</th>\n","      <td>ks08</td>\n","      <td>0</td>\n","      <td>*</td>\n","      <td>Two drops sanitize anything in your house.</td>\n","    </tr>\n","    <tr>\n","      <th>6719</th>\n","      <td>m_02</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>The cottage which Mrs Dashwood accepted was ra...</td>\n","    </tr>\n","    <tr>\n","      <th>6103</th>\n","      <td>c_13</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>The puppy was kissed by the policeman.</td>\n","    </tr>\n","    <tr>\n","      <th>4500</th>\n","      <td>ks08</td>\n","      <td>0</td>\n","      <td>*</td>\n","      <td>Lee not left.</td>\n","    </tr>\n","    <tr>\n","      <th>5376</th>\n","      <td>b_73</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>He gave me more of his marbles than I wanted.</td>\n","    </tr>\n","    <tr>\n","      <th>8128</th>\n","      <td>ad03</td>\n","      <td>0</td>\n","      <td>*</td>\n","      <td>I assumed to be innocent</td>\n","    </tr>\n","    <tr>\n","      <th>6027</th>\n","      <td>c_13</td>\n","      <td>0</td>\n","      <td>*</td>\n","      <td>The cat was having eaten.</td>\n","    </tr>\n","    <tr>\n","      <th>918</th>\n","      <td>bc01</td>\n","      <td>0</td>\n","      <td>?*</td>\n","      <td>Although I don't know which book Sam did, I do...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     sentence_source  ...                                           sentence\n","64              gj04  ...                        Bill floated into the cave.\n","1103            r-67  ...                       John is taller than Bill is.\n","4155            ks08  ...         Two drops sanitize anything in your house.\n","6719            m_02  ...  The cottage which Mrs Dashwood accepted was ra...\n","6103            c_13  ...             The puppy was kissed by the policeman.\n","4500            ks08  ...                                      Lee not left.\n","5376            b_73  ...      He gave me more of his marbles than I wanted.\n","8128            ad03  ...                           I assumed to be innocent\n","6027            c_13  ...                          The cat was having eaten.\n","918             bc01  ...  Although I don't know which book Sam did, I do...\n","\n","[10 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"-cVDneh8x5kh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":80},"outputId":"469200b4-81c7-4311-d2ba-f2a69b0508a1","executionInfo":{"status":"ok","timestamp":1577742500023,"user_tz":480,"elapsed":3840,"user":{"displayName":"Xin Heng","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQvHFMPmbZ2ZkxcYliAOrSQhkYHgGNGai5QhEn=s64","userId":"10806682243950504635"}}},"source":["from transformers import BertTokenizer\n","print(\"Loading the BERT tokenizer...\")\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)"],"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Loading the BERT tokenizer...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eIN9urBQx_Fk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"7d97a4ac-9550-4c31-db9f-b75d6b59085c","executionInfo":{"status":"ok","timestamp":1577742563616,"user_tz":480,"elapsed":968,"user":{"displayName":"Xin Heng","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQvHFMPmbZ2ZkxcYliAOrSQhkYHgGNGai5QhEn=s64","userId":"10806682243950504635"}}},"source":["# Get the lists of sentences and their labels.\n","sentences = df.sentence.values\n","labels = df.label.values\n","\n","print('Original:  ', sentences[0])\n","print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n","print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Original:   Our friends won't buy this analysis, let alone the next one we propose.\n","Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n","Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w3Xp7dK8yPUK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"a0e1fa8b-f2d8-4df7-d7ce-5090dcbeaea4","executionInfo":{"status":"ok","timestamp":1577742685245,"user_tz":480,"elapsed":2549,"user":{"displayName":"Xin Heng","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQvHFMPmbZ2ZkxcYliAOrSQhkYHgGNGai5QhEn=s64","userId":"10806682243950504635"}}},"source":["# Sentences to IDs: Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","for sent in sentences:\n","    # `encode` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    encoded_sent = tokenizer.encode(\n","        sent,                      # Sentence to encode.\n","        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                   )\n","    input_ids.append(encoded_sent)\n","\n","# Print sentence 0, now as a list of IDs.\n","print(\"Original: \", sentences[0])\n","print(\"Token IDs:\", input_ids[0])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Original:  Our friends won't buy this analysis, let alone the next one we propose.\n","Token IDs: [101, 2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012, 102]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ehn786PTysnt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"74997e61-48e7-4c37-9b71-d12f155039aa","executionInfo":{"status":"ok","timestamp":1577742750226,"user_tz":480,"elapsed":1001,"user":{"displayName":"Xin Heng","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQvHFMPmbZ2ZkxcYliAOrSQhkYHgGNGai5QhEn=s64","userId":"10806682243950504635"}}},"source":["# We'll borrow the `pad_sequences` utility function\n","from keras.preprocessing.sequence import pad_sequences\n","\n","# Set the maximum sequence length.\n","MAX_LEN = 64\n","print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n","print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n","\n","# Pad our input tokens with value 0.\n","# \"post\" indicates that we want to pad and truncate at the end of the sequence, as opposed to the beginning.\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n","\n","print('Successfully finished with padding')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["\n","Padding/truncating all sentences to 64 values...\n","\n","Padding token: \"[PAD]\", ID: 0\n","Successfully finished with padding\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"2QoGy1kgy83P","colab_type":"code","colab":{}},"source":["# Create attention masks\n","attention_masks = []\n","\n","# For each sentence...\n","for sent in input_ids:\n","    \n","    # Create the attention mask.\n","    #   - If a token ID is 0, then it's padding, set the mask to 0.\n","    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n","    att_mask = [int(token_id > 0) for token_id in sent]\n","    \n","    # Store the attention mask for this sentence.\n","    attention_masks.append(att_mask)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h_7ctClazEMp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"a3f4e85f-54bd-4a6a-a731-a3bb8531b765","executionInfo":{"status":"ok","timestamp":1577742885443,"user_tz":480,"elapsed":983,"user":{"displayName":"Xin Heng","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQvHFMPmbZ2ZkxcYliAOrSQhkYHgGNGai5QhEn=s64","userId":"10806682243950504635"}}},"source":["# Use train_test_split to split our data into train and validation sets\n","from sklearn.model_selection import train_test_split\n","train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(\n","    input_ids, labels, random_state=2018, test_size=0.1\n","    )\n","train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, random_state=2018, test_size=0.1)\n","\n","# Convert all inputs and labels into torch tensors, the required data types\n","train_inputs = torch.tensor(train_inputs)\n","validation_inputs = torch.tensor(validation_inputs)\n","train_labels = torch.tensor(train_labels)\n","validation_labels = torch.tensor(validation_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_masks = torch.tensor(validation_masks)\n","print(\"Succcessfully finished with train test splitting\")"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Succcessfully finished with train test splitting\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YHO3_qdMzd4F","colab_type":"code","colab":{}},"source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it here.\n","# For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n","batch_size = 32\n","\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pPZLsyapzpEW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"d62daed4-42c6-41e6-f8f5-b983aaaa69f6","executionInfo":{"status":"ok","timestamp":1577743002721,"user_tz":480,"elapsed":27659,"user":{"displayName":"Xin Heng","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQvHFMPmbZ2ZkxcYliAOrSQhkYHgGNGai5QhEn=s64","userId":"10806682243950504635"}}},"source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n","model = BertForSequenceClassification.from_pretrained(\n","    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels = 2, # 2 for binary classification.\n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"wNEo6r-mzz_y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":612},"outputId":"a796e6b3-8273-4af9-dc85-8ba6436d0694","executionInfo":{"status":"ok","timestamp":1577743011897,"user_tz":480,"elapsed":901,"user":{"displayName":"Xin Heng","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQvHFMPmbZ2ZkxcYliAOrSQhkYHgGNGai5QhEn=s64","userId":"10806682243950504635"}}},"source":["# Get all of the model's parameters as a list of tuples.\n","params = list(model.named_parameters())\n","print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n","print('==== Embedding Layer ====\\n')\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","print('\\n==== First Transformer ====\\n')\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","print('\\n==== Output Layer ====\\n')\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["The BERT model has 201 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","bert.embeddings.word_embeddings.weight                  (30522, 768)\n","bert.embeddings.position_embeddings.weight                (512, 768)\n","bert.embeddings.token_type_embeddings.weight                (2, 768)\n","bert.embeddings.LayerNorm.weight                              (768,)\n","bert.embeddings.LayerNorm.bias                                (768,)\n","\n","==== First Transformer ====\n","\n","bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.query.bias                (768,)\n","bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n","bert.encoder.layer.0.attention.self.key.bias                  (768,)\n","bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.value.bias                (768,)\n","bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n","bert.encoder.layer.0.attention.output.dense.bias              (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n","bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n","bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n","bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n","bert.encoder.layer.0.output.dense.bias                        (768,)\n","bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n","bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n","\n","==== Output Layer ====\n","\n","bert.pooler.dense.weight                                  (768, 768)\n","bert.pooler.dense.bias                                        (768,)\n","classifier.weight                                           (2, 768)\n","classifier.bias                                                 (2,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8-Kg-E4Jz8xb","colab_type":"code","colab":{}},"source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) I believe the 'W' stands for 'Weight Decay fix\"\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )\n","from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs (authors recommend between 2 and 4)\n","epochs = 4\n","# Total number of training steps is number of batches * number of epochs.\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)\n","import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''Takes a time in seconds and returns a string hh:mm:ss'''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pIOAvI_C0UK-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"d02cca11-768c-4f1a-ce59-ba48ab445361","executionInfo":{"status":"ok","timestamp":1577743375753,"user_tz":480,"elapsed":232600,"user":{"displayName":"Xin Heng","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQvHFMPmbZ2ZkxcYliAOrSQhkYHgGNGai5QhEn=s64","userId":"10806682243950504635"}}},"source":["import random\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# Store the average loss after each epoch so we can plot them.\n","loss_values = []\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # This will return the loss (rather than the model output) because we\n","        # have provided the `labels`.\n","        # The documentation for this `model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        outputs = model(b_input_ids, \n","                    token_type_ids=None, \n","                    attention_mask=b_input_mask, \n","                    labels=b_labels)\n","        \n","        # The call to `model` always returns a tuple, so we need to pull the \n","        # loss value out of the tuple.\n","        loss = outputs[0]\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over the training data.\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","    \n","    # Store the loss value for plotting the learning curve.\n","    loss_values.append(avg_train_loss)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Add batch to GPU\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        # Telling the model not to compute or store gradients, saving memory and\n","        # speeding up validation\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # This will return the logits rather than the loss because we have\n","            # not provided labels.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here: \n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask)\n","        \n","        # Get the \"logits\" output by the model. The \"logits\" are the output\n","        # values prior to applying an activation function like the softmax.\n","        logits = outputs[0]\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        # Calculate the accuracy for this batch of test sentences.\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        \n","        # Accumulate the total accuracy.\n","        eval_accuracy += tmp_eval_accuracy\n","\n","        # Track the number of batches\n","        nb_eval_steps += 1\n","\n","    # Report the final accuracy for this validation run.\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\\nTraining complete!\\n\")"],"execution_count":23,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 4 ========\n","Training...\n","  Batch    40  of    241.    Elapsed: 0:00:09.\n","  Batch    80  of    241.    Elapsed: 0:00:19.\n","  Batch   120  of    241.    Elapsed: 0:00:28.\n","  Batch   160  of    241.    Elapsed: 0:00:37.\n","  Batch   200  of    241.    Elapsed: 0:00:47.\n","  Batch   240  of    241.    Elapsed: 0:00:56.\n","\n","  Average training loss: 0.50\n","  Training epcoh took: 0:00:56\n","\n","Running Validation...\n","  Accuracy: 0.80\n","  Validation took: 0:00:02\n","\n","======== Epoch 2 / 4 ========\n","Training...\n","  Batch    40  of    241.    Elapsed: 0:00:09.\n","  Batch    80  of    241.    Elapsed: 0:00:19.\n","  Batch   120  of    241.    Elapsed: 0:00:28.\n","  Batch   160  of    241.    Elapsed: 0:00:37.\n","  Batch   200  of    241.    Elapsed: 0:00:47.\n","  Batch   240  of    241.    Elapsed: 0:00:56.\n","\n","  Average training loss: 0.31\n","  Training epcoh took: 0:00:56\n","\n","Running Validation...\n","  Accuracy: 0.82\n","  Validation took: 0:00:02\n","\n","======== Epoch 3 / 4 ========\n","Training...\n","  Batch    40  of    241.    Elapsed: 0:00:10.\n","  Batch    80  of    241.    Elapsed: 0:00:19.\n","  Batch   120  of    241.    Elapsed: 0:00:28.\n","  Batch   160  of    241.    Elapsed: 0:00:38.\n","  Batch   200  of    241.    Elapsed: 0:00:47.\n","  Batch   240  of    241.    Elapsed: 0:00:56.\n","\n","  Average training loss: 0.19\n","  Training epcoh took: 0:00:56\n","\n","Running Validation...\n","  Accuracy: 0.82\n","  Validation took: 0:00:02\n","\n","======== Epoch 4 / 4 ========\n","Training...\n","  Batch    40  of    241.    Elapsed: 0:00:09.\n","  Batch    80  of    241.    Elapsed: 0:00:19.\n","  Batch   120  of    241.    Elapsed: 0:00:28.\n","  Batch   160  of    241.    Elapsed: 0:00:37.\n","  Batch   200  of    241.    Elapsed: 0:00:47.\n","  Batch   240  of    241.    Elapsed: 0:00:56.\n","\n","  Average training loss: 0.12\n","  Training epcoh took: 0:00:56\n","\n","Running Validation...\n","  Accuracy: 0.82\n","  Validation took: 0:00:02\n","\n","Training complete!\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bwC0q7yM0dB7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":427},"outputId":"ac50dbfa-980e-40e1-a6a8-3bf7fdb2860a","executionInfo":{"status":"ok","timestamp":1577743377190,"user_tz":480,"elapsed":1435,"user":{"displayName":"Xin Heng","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQvHFMPmbZ2ZkxcYliAOrSQhkYHgGNGai5QhEn=s64","userId":"10806682243950504635"}}},"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","sns.set(style='darkgrid')\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","plt.plot(loss_values, 'b-o')\n","plt.title(\"Training loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","\n","plt.show()"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 864x432 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"nsM7SJCj0wtc","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}